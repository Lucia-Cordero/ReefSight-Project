{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ac395a3-5a84-47f8-8e52-9534cbb64bbd",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a6c8be6-7c06-49e5-b0b4-021cc853241c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run this notebook, follow the next steps:\n",
    "# 1. You need to download the archive.zip file from https://www.kaggle.com/datasets/sonainjamil/bleached-corals-detection\n",
    "# 2. Create a folder named 'Bleached_and_Unbleached_Corals_Classification/' inside the 'raw_data' folder\n",
    "# 3. Copy the archive.zip file into the 'Bleached_and_Unbleached_Corals_Classification/' folder\n",
    "# 4. Define the 'path_data' variable below with the path to the 'raw_data/Bleached_and_Unbleached_Corals_Classification/' folder on your local machine.\n",
    "\n",
    "# path_data = '/Users/carloschutz/code/Lucia-Cordero/ReefSight-Project/raw_data/Bleached_and_Unbleached_Corals_Classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88e4da16-8a5f-4672-be8c-969d7048f9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-11 14:34:33.360974: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-11 14:34:33.475850: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-11 14:34:33.615340: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-12-11 14:34:33.757199: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-12-11 14:34:33.757987: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-11 14:34:33.991862: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-11 14:34:35.616379: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../code/Lucia-Cordero/ReefSight-Project/raw_data/Bleached_and_Unbleached_Corals_Classification:'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 17\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# 1. Data Loading and Preprocessing (Unchanged)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../code/Lucia-Cordero/ReefSight-Project/raw_data/Bleached_and_Unbleached_Corals_Classification:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContents of data_dir:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     18\u001b[0m image_size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)\n\u001b[1;32m     19\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../code/Lucia-Cordero/ReefSight-Project/raw_data/Bleached_and_Unbleached_Corals_Classification:'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. Data Loading and Preprocessing (Unchanged)\n",
    "# ==============================================================================\n",
    "\n",
    "data_dir = \"../code/Lucia-Cordero/ReefSight-Project/raw_data/Bleached_and_Unbleached_Corals_Classification:\"\n",
    "\n",
    "print(\"Contents of data_dir:\", os.listdir(data_dir))\n",
    "image_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=42,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode=\"binary\",\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=42,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode=\"binary\",\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(\"Classes:\", class_names)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.prefetch(AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(AUTOTUNE)\n",
    "\n",
    "# --- Hyperparameters ---\n",
    "input_shape = image_size + (3,)\n",
    "# We will use a lower learning rate for fine-tuning to prevent feature damage.\n",
    "initial_learning_rate = 1e-4\n",
    "fine_tune_learning_rate = 1e-5\n",
    "epochs_initial_train = 10  # Reduced for faster demonstration, adjust as needed\n",
    "epochs_fine_tune = 20      # Additional epochs for fine-tuning\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. Data Augmentation and Model Definition (Modified)\n",
    "# ==============================================================================\n",
    "\n",
    "# Data Augmentation layer (This is applied directly to the model input)\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "    layers.RandomContrast(0.1),\n",
    "], name=\"data_augmentation\")\n",
    "\n",
    "def create_vgg16_frozen_model(input_shape, learning_rate):\n",
    "    \"\"\"Creates the VGG16 model with the base frozen for initial training.\"\"\"\n",
    "\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Note: Augmentation is applied to input *before* VGG preprocessing\n",
    "    x = data_augmentation(inputs)\n",
    "    x = preprocess_input(x) # VGG-specific preprocessing\n",
    "\n",
    "    base_model = VGG16(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_tensor=x # The input tensor is the output of VGG preprocessing\n",
    "    )\n",
    "    # CRITICAL: Freeze the base model for the first training phase\n",
    "    base_model.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. Initial Training (Frozen Base)\n",
    "# ==============================================================================\n",
    "\n",
    "vgg_aug_model = create_vgg16_frozen_model(input_shape, initial_learning_rate)\n",
    "vgg_aug_model.summary()\n",
    "\n",
    "# Define paths and callbacks for the INITIAL phase\n",
    "model_save_path = os.path.join(data_dir, \"models\", \"vgg16_augmented_initial_best.keras\")\n",
    "\n",
    "initial_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=5, # Shorter patience for initial phase\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        model_save_path,\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(\"\\n--- Starting Initial Training (Frozen Base) ---\")\n",
    "history_initial = vgg_aug_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs_initial_train,\n",
    "    callbacks=initial_callbacks,\n",
    ")\n",
    "\n",
    "# Load the best weights from the initial training run\n",
    "vgg_aug_model.load_weights(model_save_path)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. Fine-Tuning (Unfrozen Base with Augmentation)\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n--- Starting Fine-Tuning Phase (Unfrozen Base) ---\")\n",
    "\n",
    "# Step 4a: Unfreeze the base model\n",
    "vgg_aug_model.layers[2].trainable = True # Index 2 is the VGG16 model\n",
    "\n",
    "# Step 4b: Re-compile the model with a lower learning rate\n",
    "vgg_aug_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(fine_tune_learning_rate), # CRITICAL: Lower LR\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "# vgg_aug_model.summary(expand_nested=True) # Optional: Show which layers are now trainable\n",
    "\n",
    "# Define callbacks for the FINE-TUNING phase\n",
    "model_fine_tune_save_path = os.path.join(data_dir, \"models\", \"vgg16_augmented_final_best.keras\")\n",
    "\n",
    "fine_tune_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=10, # Longer patience for fine-tuning\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        model_fine_tune_save_path,\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Step 4c: Continue training from the saved initial weights\n",
    "history_fine_tune = vgg_aug_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs_initial_train + epochs_fine_tune, # Run for the total number of desired epochs\n",
    "    initial_epoch=history_initial.epoch[-1],        # Start from where the initial training stopped\n",
    "    callbacks=fine_tune_callbacks,\n",
    ")\n",
    "\n",
    "# Load the FINAL best weights\n",
    "vgg_aug_model.load_weights(model_fine_tune_save_path)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. Evaluation (Final Model)\n",
    "# ==============================================================================\n",
    "\n",
    "val_loss, val_acc = vgg_aug_model.evaluate(val_ds)\n",
    "print(\"\\nValidation loss (Final Augmented Model):\", val_loss)\n",
    "print(\"Validation accuracy (Final Augmented Model):\", val_acc)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 6. Plotting and Visualization (Adapted to combine history)\n",
    "# ==============================================================================\n",
    "\n",
    "# Concatenate histories for combined plotting\n",
    "def combine_histories(h1, h2):\n",
    "    \"\"\"Combines two history objects for continuous plotting.\"\"\"\n",
    "    h1_df = pd.DataFrame(h1.history)\n",
    "    h2_df = pd.DataFrame(h2.history)\n",
    "    return pd.concat([h1_df, h2_df], ignore_index=True)\n",
    "\n",
    "combined_history_df = combine_histories(history_initial, history_fine_tune)\n",
    "\n",
    "def plot_combined_history(df):\n",
    "    df[\"epoch\"] = range(1, len(df) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(df[\"epoch\"], df[\"accuracy\"], label=\"Train\")\n",
    "    plt.plot(df[\"epoch\"], df[\"val_accuracy\"], label=\"Val\")\n",
    "    plt.axvline(x=history_initial.epoch[-1] + 1, color='r', linestyle='--', label='Fine-Tune Start')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Accuracy over epochs (Augmented/Fine-Tuned)\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "\n",
    "    # Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(df[\"epoch\"], df[\"loss\"], label=\"Train\")\n",
    "    plt.plot(df[\"epoch\"], df[\"val_loss\"], label=\"Val\")\n",
    "    plt.axvline(x=history_initial.epoch[-1] + 1, color='r', linestyle='--')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Loss over epochs (Augmented/Fine-Tuned)\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_combined_history(combined_history_df)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 7. Single Prediction Example (Unchanged)\n",
    "# ==============================================================================\n",
    "# This section uses the FINAL best model saved to vgg16_augmented_final_best.keras\n",
    "\n",
    "best_model_path = model_fine_tune_save_path # Use the final saved path\n",
    "model = tf.keras.models.load_model(best_model_path)\n",
    "\n",
    "\n",
    "if 'class_names' not in globals():\n",
    "    # ... (logic to determine class_names) ...\n",
    "    class_names = train_ds.class_names # Assuming train_ds is still available\n",
    "\n",
    "\n",
    "images, labels = next(iter(val_ds))\n",
    "idx = random.randint(0, len(images) - 1)\n",
    "img = images[idx]\n",
    "true_label = int(labels[idx].numpy())\n",
    "\n",
    "prob = float(model.predict(tf.expand_dims(img, 0))[0, 0])\n",
    "pred_label = int(prob >= 0.5)\n",
    "\n",
    "\n",
    "bleached_idx = class_names.index(\"Bleached\") if \"Bleached\" in class_names else 1\n",
    "\n",
    "if bleached_idx == 1:\n",
    "    p_bleached = prob\n",
    "else:\n",
    "    p_bleached = 1 - prob\n",
    "\n",
    "print(\"\\n--- Final Model Prediction Sample ---\")\n",
    "print(\"True:\", class_names[true_label])\n",
    "print(\"Pred:\", class_names[pred_label])\n",
    "print(f\"Bleached probability: {p_bleached*100:.2f}%\")\n",
    "print(f\"Unbleached probability: {(1 - p_bleached)*100:.2f}%\")\n",
    "\n",
    "plt.imshow(img.numpy().astype(\"uint8\"))\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ReefSight-Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
